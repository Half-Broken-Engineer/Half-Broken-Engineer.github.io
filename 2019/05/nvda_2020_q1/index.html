<!DOCTYPE html>
<html lang="ja">
  <head>
    
    <script type="application/ld+json">

{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "NVDA_2020_Q1",
  
  "datePublished": "2019-05-16T23:49:07-04:00",
  "dateModified": "2019-05-16T23:49:07-04:00",
  "author": {
    "@type": "Person",
    "name": "Half-Broken Engineer",
    
    "image": "https://half-broken-engineer.github.io/img/profile.png"
    
  },
  "mainEntityOfPage": { 
    "@type": "WebPage",
    "@id": "https:\/\/half-broken-engineer.github.io\/2019\/05\/nvda_2020_q1\/" 
  },
  "publisher": {
    "@type": "Organization",
    "name": "Â£ä„Çå„Åã„Åë„ÅÆ„Ç®„É≥„Ç∏„Éã„Ç¢„ÅÆ„É≠„Ç∞",
    
    "logo": {
      "@type": "ImageObject",
      "url": "https://half-broken-engineer.github.io/img/profile.png"
    }
    
  },
  "description": "Operator: Good afternoon. My name is Kristina, and I\u0026rsquo;ll be your conference operator today. Welcome to NVIDIA\u0026rsquo;s financial results conference call. All lines have been placed on mute. [Operator Instructions] I\u0026rsquo;ll now turn the call over to Simona Jankowski from Investor Relations to begin your conference.\nSimona Jankowski: Thank you. Good afternoon, everyone. And welcome to NVIDIA\u0026rsquo;s conference call for the first quarter of fiscal 2020. With me on the call today from NVIDIA are Jen-Hsun Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer.",
  "keywords": []
}

</script>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.112.5 with theme Tranquilpeak 0.5.3-BETA">
<meta name="author" content="Half-Broken Engineer">
<meta name="keywords" content="">
<meta name="description" content="Operator: Good afternoon. My name is Kristina, and I&rsquo;ll be your conference operator today. Welcome to NVIDIA&rsquo;s financial results conference call. All lines have been placed on mute. [Operator Instructions] I&rsquo;ll now turn the call over to Simona Jankowski from Investor Relations to begin your conference.
Simona Jankowski: Thank you. Good afternoon, everyone. And welcome to NVIDIA&rsquo;s conference call for the first quarter of fiscal 2020. With me on the call today from NVIDIA are Jen-Hsun Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer.">


<meta property="og:description" content="Operator: Good afternoon. My name is Kristina, and I&rsquo;ll be your conference operator today. Welcome to NVIDIA&rsquo;s financial results conference call. All lines have been placed on mute. [Operator Instructions] I&rsquo;ll now turn the call over to Simona Jankowski from Investor Relations to begin your conference.
Simona Jankowski: Thank you. Good afternoon, everyone. And welcome to NVIDIA&rsquo;s conference call for the first quarter of fiscal 2020. With me on the call today from NVIDIA are Jen-Hsun Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer.">
<meta property="og:type" content="article">
<meta property="og:title" content="NVDA_2020_Q1">
<meta name="twitter:title" content="NVDA_2020_Q1">
<meta property="og:url" content="https://half-broken-engineer.github.io/2019/05/nvda_2020_q1/">
<meta property="twitter:url" content="https://half-broken-engineer.github.io/2019/05/nvda_2020_q1/">
<meta property="og:site_name" content="Â£ä„Çå„Åã„Åë„ÅÆ„Ç®„É≥„Ç∏„Éã„Ç¢„ÅÆ„É≠„Ç∞">
<meta property="og:description" content="Operator: Good afternoon. My name is Kristina, and I&rsquo;ll be your conference operator today. Welcome to NVIDIA&rsquo;s financial results conference call. All lines have been placed on mute. [Operator Instructions] I&rsquo;ll now turn the call over to Simona Jankowski from Investor Relations to begin your conference.
Simona Jankowski: Thank you. Good afternoon, everyone. And welcome to NVIDIA&rsquo;s conference call for the first quarter of fiscal 2020. With me on the call today from NVIDIA are Jen-Hsun Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer.">
<meta name="twitter:description" content="Operator: Good afternoon. My name is Kristina, and I&rsquo;ll be your conference operator today. Welcome to NVIDIA&rsquo;s financial results conference call. All lines have been placed on mute. [Operator Instructions] I&rsquo;ll now turn the call over to Simona Jankowski from Investor Relations to begin your conference.
Simona Jankowski: Thank you. Good afternoon, everyone. And welcome to NVIDIA&rsquo;s conference call for the first quarter of fiscal 2020. With me on the call today from NVIDIA are Jen-Hsun Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer.">
<meta property="og:locale" content="ja">

  
    <meta property="article:published_time" content="2019-05-16T23:49:07">
  
  
    <meta property="article:modified_time" content="2019-05-16T23:49:07">
  
  
  
    
      <meta property="article:section" content="transcript">
    
      <meta property="article:section" content="earning call">
    
  
  
    
      <meta property="article:tag" content="NVDA">
    
  


<meta name="twitter:card" content="summary">

  <meta name="twitter:site" content="@overcome_kidney">


  <meta name="twitter:creator" content="@overcome_kidney">






  <meta property="og:image" content="https://half-broken-engineer.github.io/img/profile.png">
  <meta property="twitter:image" content="https://half-broken-engineer.github.io/img/profile.png">






    <title>NVDA_2020_Q1</title>

    <link rel="icon" href="https://half-broken-engineer.github.io/favicon.png">
    

    

    <link rel="canonical" href="https://half-broken-engineer.github.io/2019/05/nvda_2020_q1/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    
    
    <link rel="stylesheet" href="https://half-broken-engineer.github.io/css/style-h6ccsoet3mzkbb0wngshlfbaweimexgqcxj0h5hu4h82olsdzz6wmqdkajm.min.css" />
    
    
      
        <link rel="stylesheet"  href="https://half-broken-engineer.github.io/css/mystyle.css">
      
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="5">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://half-broken-engineer.github.io/" aria-label="„Éõ„Éº„É†„Éö„Éº„Ç∏„Å∏">Â£ä„Çå„Åã„Åë„ÅÆ„Ç®„É≥„Ç∏„Éã„Ç¢„ÅÆ„É≠„Ç∞</a>
  </div>
  
    
      <a class="header-right-picture "
         href="https://half-broken-engineer.github.io/#about" aria-label="„É™„É≥„ÇØ„ÇíÈñã„Åè: /#about">
    
    
    
      
        <img class="header-picture" src="https://half-broken-engineer.github.io/img/profile.png" alt="„Éó„É≠„Éï„Ç£„Éº„É´ÁîªÂÉè" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="5">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://half-broken-engineer.github.io/#about" aria-label="ËëóËÄÖ„Å´„Å§„ÅÑ„Å¶„ÇÇ„Å£„Å®Ë™≠„ÇÄ">
          <img class="sidebar-profile-picture" src="https://half-broken-engineer.github.io/img/profile.png" alt="„Éó„É≠„Éï„Ç£„Éº„É´ÁîªÂÉè" />
        </a>
        <h4 class="sidebar-profile-name">Half-Broken Engineer</h4>
        
          <h5 class="sidebar-profile-bio">ü§ñ„ÄÄ„ÄÄ„ÄÄ„ÄÄÂ£ä„Çå„Åã„Åë„ÅÆ„Ç®„É≥„Ç∏„Éã„Ç¢„ÄÄ„ÄÄ„ÄÄ„ÄÄüíª‰∏çÂÆâ„ÇíËß£Ê∂à„Åó„Åü„ÅÑ„Åã„Çâüí∞„ÅÆ„ÅäÂãâÂº∑„ÇÇ„Åô„Çã</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://half-broken-engineer.github.io/" title="Home">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">„Éõ„Éº„É†</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://half-broken-engineer.github.io/categories" title="Categories">
    
      <i class="sidebar-button-icon fas fa-lg fa-bookmark" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">„Ç´„ÉÜ„Ç¥„É™„Éº</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://half-broken-engineer.github.io/tags" title="Tags">
    
      <i class="sidebar-button-icon fas fa-lg fa-tags" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">„Çø„Ç∞</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://half-broken-engineer.github.io/archives" title="Archives">
    
      <i class="sidebar-button-icon fas fa-lg fa-archive" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">„Ç¢„Éº„Ç´„Ç§„Éñ</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://half-broken-engineer.github.io/#about" title="About">
    
      <i class="sidebar-button-icon fas fa-lg fa-question" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">„Éó„É≠„Éï„Ç£„Éº„É´</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/Half-Broken-Engineer" target="_blank" rel="noopener" title="GitHub">
    
      <i class="sidebar-button-icon fab fa-lg fa-github" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://half-broken-engineer.github.io/index.xml" title="RSS">
    
      <i class="sidebar-button-icon fas fa-lg fa-rss" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>


    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="5"
        class="
               hasCoverMetaIn
               ">
        <article class="post" id="top">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title">
      NVDA_2020_Q1
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time datetime="2019-05-16T23:49:07-04:00">
        
  
  
  
  
    2019-05-16
  

      </time>
    
    
  
  
    <span>„Ç´„ÉÜ„Ç¥„É™„Éº</span>
    
      <a class="category-link" href="https://half-broken-engineer.github.io/categories/transcript">transcript</a>, 
    
      <a class="category-link" href="https://half-broken-engineer.github.io/categories/earning-call">earning call</a>
    
  

  </div>

</div>
          
          <div class="post-content markdown">
            <div class="main-content-wrap">
              <p>Operator: Good afternoon. My name is Kristina, and I&rsquo;ll be your conference operator today. Welcome to NVIDIA&rsquo;s financial results conference call. All lines have been placed on mute. [Operator Instructions] I&rsquo;ll now turn the call over to Simona Jankowski from Investor Relations to begin your conference.</p>
<p>Simona Jankowski: Thank you. Good afternoon, everyone. And welcome to NVIDIA&rsquo;s conference call for the first quarter of fiscal 2020. With me on the call today from NVIDIA are Jen-Hsun Huang, President and Chief Executive Officer and Colette Kress, Executive Vice President and Chief Financial Officer. I&rsquo;d like to remind you that our call is being webcast live on NVIDIA&rsquo;s Investor Relations Web site. The webcast will be available for replay until the conference call to discuss our financial results for the second quarter of fiscal 2020. The content of today&rsquo;s call is NVIDIA&rsquo;s property. It can&rsquo;t be reproduced or transcribed without our prior written consent. During this call, we may make forward-looking statements based on current expectations. These are subject to a number of significant risks and uncertainties and our actual results may differ materially. For a discussion of factors that could affect our future financial results and business, please refer to the disclosure in today&rsquo;s earnings release, our most recent Forms 10-K and 10-Q and the reports that we may file on Form 8-K with Securities and Exchange Commission. All our statements are made as of today, May 16, 2019, based on information currently available to us. Except as required by law, we assume no obligation to update any such statements. During this call, we will discuss non-GAAP financial measures. You can find a reconciliation of these non-GAAP financial measures to GAAP financial measures in our CFO commentary, which is posted on our Web site. With that, let me turn the call over to Colette.</p>
<p>Colette Kress: Thanks Simona. Q1 revenue was $2.2 billion in line with our outlook and down 31% year-on-year and up 1% sequentially. Starting with our gaming business, revenue of $1.05 billion was down 39% year-on-year and up 11% sequentially consistent with our expectations. We are pleased with the initial ramp of Turing and the reduction of inventory in the channel. During the quarter, we filled out our touring lineup with the launch of mid-range GeForce products that enable us to delight gamers with the best performance at every price point starting at $149. New product launches this quarter included the GeForce GTX 1660 Ti, 1660 and 1650 which bring Turing to the high volume PC gaming side for both desktops and laptops. These GPUs deliver up to 50% performance improvement over their Pascal based predecessors leveraging new Shader innovations such as concurrent floating point and integer operations, a unified cache and adaptive shading all with the incredibly power efficient architecture. We expect continued growth in the gaming laptops this year. GeForce gaming laptops are one of the shining spots of the consumer PC market. This year OEMs have built a record of nearly 100 GeForce gaming laptops. GeForce laptops start at $799 and all the way up to an amazing GeForce RTX 2080 4K laptops that are more powerful than even next generation consoles. The content ecosystem for Ray traced games is gaining significant momentum. At the March game developers conference, Ray tracing sessions were packed. Support for Ray tracing was announced by the industry&rsquo;s most important game engines, Microsoft DSR, Epics on unreal engine and unity. Ray tracing will be the standard for next generation games. In March at our GPU technology conference, we also announced more details on our cloud gaming strategy through our GeForce NOW service and the newly announced [indiscernible] alliance. GeForce NOW is a GeForce gaming PC in the cloud for the 1 billion PCs that are not game ready expanding our reach well beyond today&rsquo;s 200 million GeForce gamers. It&rsquo;s an open platform that allows gamers to play the games they own instantly in the cloud on any PC or Mac anywhere they like. The service currently has 300,000 monthly active users with 1 million more on the waitlist. To scale out to millions of gamers worldwide, we announced the GeForce NOW alliance expanding GFN through partnerships with the global telecom providers, SoftBank in Japan and LG UPlus in South Korea will be among the first to launch GFN later this year. NVIDIA, we&rsquo;ll develop the software and manage the service and share the subscription revenue with alliance partners. GFN runs on NVIDIA&rsquo;s edge computing servers as telcos raise to offer the new services for their 5G networks, GFN is an ideal new 5G application. Moving to data center, revenue was $634 million down 10% year-on-year and down 7% sequentially reflecting the pause in hyperscale spending. While demand from some hyperscale customers bounced back nicely, others paused or cut back. Despite the uneven demand backdrop, the quarter had significant positives consistent with the growth drivers we outlined on our previous earnings call. First, inference revenue was up sharply both year-on-year and sequentially with broad based adoption across a number of hyperscale and consumer internet companies. As announced at GTC, Amazon and Alibaba joined other hyperscale such as Google, Baidu and Tencent in adopting the T4 in their data centers. A growing list of consumer Internet companies is also adopting our GPUs for influence including LinkedIn, Expedia Microsoft, PayPal, Pinterest, Snap and Twitter. The contribution of inference to our data center revenue is now well into the double-digit percent. Second, we expanded our reach in enterprise teaming up with major OEMs to introduce the T4 enterprise and edge computing servers. These are optimized to run the NVIDIA CUDA-X AI acceleration libraries for AI and data analytics. Within easy to deploy software stack from NVIDIA and our ecosystem partners, this wave of NVIDIA edge AI computing systems enables companies in the world&rsquo;s largest industries, transportation, manufacturing, industrial, retail, healthcare and agricultural to bring intelligence to the edge where the customers operate. And third, we made significant progress in data center rendering and graphics. We unveiled a new RTX server configuration packing 40 GPUs into an 8-used space and up to 32 servers in a pod providing unparalleled density, efficiency and scalability. With a complete stack, this server design is optimized for three data center graphic workflows rendering, remote, workstation and cloud gaming. The rendering opportunity is starting to take shape with early RTX server deployment at leading studios, including Disney, Pixar and [indiscernible]. In the quarter, we announced our pending acquisition of Mellanox for $125 per share in cash representing a total enterprise value of approximately $6.9 billion, which we believe will strengthen our strategic position in data center. Once complete the acquisition, we will unite two of the world&rsquo;s leading companies in high performance computing. Together NVIDIA&rsquo;s computing platform and Mellanox&rsquo;s interconnects power over 250 of the world&rsquo;s top 500 supercomputers and have as customers every major cloud service provider and computer maker. Data centers in the future will be architect as giant compute engines with tens and thousands of compute nodes, designed holistically with their interconnects for optimal performance. With Mellanox, NVIDIA will optimize data center scale workloads, across the entire computing networking and storage stack to achieve higher performance, greater utilization and lower operating costs for customers. Together we can create better AI computing systems for the cloud to enterprise to the edge. As stated at the time of the announcement, we look forward to closing the acquisition by the end of this calendar year. Moving to pro visualization. Revenue reached $266 million up 6% from a prior year and down 9% sequentially. Year-on-year growth was driven by both desktop and mobile workstations, while the sequential decline was largely seasonal. Areas of strength included the public sector, oil and gas and manufacturing. Emerging applications such as AI/AR/VR contributed an estimated 38% a pro visualization revenue. The real-time Ray tracing capabilities of RTX are a game changer for the visual effects industry and we are seeing tremendous momentum in the ecosystem. At UTC, we announced that the world&rsquo;s top 3D application providers have adopted NVIDIA RTX in their product releases set for later this year including Adobe, Autodesk Chaos group, Dassault and Pixar. With this rich software ecosystem, NVIDIA RTX is transforming the 3D market. For example, Pixar is using NVIDIA RTX Ray tracing on its upcoming films what a digital is using it for upcoming Disney projects and Siemens and x Ray trace studios users will be able to generate rendered images up to 4x faster in their product design workflows. We are excited to see the tremendous value in NVIDIA RTX is bringing to the millions of creators and designers served by ecosystem partners. Finally, turning to automotive, Q1 revenue was $166 million up 14% from a year ago and up 2% sequentially. Year-on-year growth was driven by growing adoption of next generation AI cockpit solutions, an autonomous vehicle development deals. At GTC we had major customer and product announcements. Toyota selected NVIDIA&rsquo;s end-to-end platform to develop train and validate self-driving vehicles. This broad partnership includes advancements in AI computing, infrastructure using NVIDIA GPUs, simulation using NVIDIA drive constellation platform and in-car AV computers based on the DRIVE AGX Xavier or Pegasus. We also announced the public availability of Drive Constellation, which enables millions of miles to be driven in virtual worlds across the broad range of scenarios with greater efficiency, cost effectiveness and safety than what&rsquo;s possible to achieve in the real world. Constellation will be reported in our data center market platform. And we introduced NVIDIA Safety Force Field, a computational defensive driving framework that shield autonomous vehicles from collisions mathematically verified and validated in simulation Safety Force Field will prevent a vehicle from creating escalating or contributing to an unsafe starting situation. We continue to believe that every vehicle will have an autonomous capability one day whether with driver or driverless. To help make that vision a reality NVIDIA has created an end-to-end platform for autonomous vehicles from AI computing infrastructure to simulation to in-car computing and Toyota is our first major win that validates the strategy. We see this as a $30 billion addressable market by 2025. Moving to the rest of the P&amp;L and balance sheet. Q1 GAAP gross margins was $58.4% and non-GAAP was 59% down year-on-year to lower gaming margins and mix up sequentially from Q4 which had $128 million charge from DRAM boards and other components. GAAP operating expenses were $938 million and non-GAAP operating expenses were $753 million up 21% and 16% year-on-year respectively. We remain on track for high single-digit OpEx growth in fiscal 2020, while continuing to invest in the key platforms driving our long-term growth. Namely graphics, AI and self-driving cars. GAAP EPS was $0.64 and non-GAAP EPS was $0.88. We did not make any stock repurchases in the quarter following the announcement of the pending Mellonox acquisition. We remain committed to returning $3 billion to shareholders through the end of fiscal 2020 in the form of dividends and repurchases. So far, we have returned $800 million through share repurchases and quarterly cash dividends. With that let me turn to the outlook for the second quarter of fiscal 2020. While we anticipate substantial quarter-over-quarter growth for Q2 outlook is somewhat lower than our expectation earlier in the quarter when our outlook for fiscal 2020 revenue was flat to down slightly from fiscal 2019. The data center spending pause around the world will likely persist in the second quarter and visibility remains low. In gaming, the CPU shortage while improving will affect the initial round of our laptop business. For Q2, we expect revenue to be $2.55 billion plus or minus 2%. We expect a stronger second half than the first half and we are returning to our practice of providing revenue outlook one quarter at a time. Q2 GAAP and non-GAAP gross margins are expected to be 59.2% and 59.5% respectively plus or minus 50 basis points. GAAP and non-GAAP operating expenses are expected to be approximately $985 million, $765 million respectively. GAAP and non-GAAP OIME or both expected to be income of approximately $27 million. GAAP and non-GAAP tax rates are both expected to be 10% plus or minus 1% excluding discrete items. Capital expenditures are expected to be approximately $120 million to $140 million. Further financial details are included in the CFO commentary and other information available on our IR Web site. In closing, let me highlight upcoming events for the financial community. We&rsquo;ll be presenting at the Bank of America Global Technology Conference on June 5; at the RBC Future of Mobility Conference on June 6; and at the NASDAQ Investor Conference on June 13. Our next earnings call to discuss financial results for the second quarter of fiscal 2020 will take place on August 15. We will now open the call for questions. Operator will you please poll.</p>
<p>Q - Aaron Rakers: Yes. Thanks for taking the question. Colette, I was wondering if you could give a little bit more color or discussion around what exactly you&rsquo;ve seen in the data center segment. And whether or not, or what you&rsquo;re looking for in terms of signs that we can kind of return to growth or maybe this pause is behind it. I guess what I&rsquo;m really asking is kind of what&rsquo;s changed over the last let&rsquo;s call it three months relative to your prior commentary from a visibility perspective and just demand perspective within that segment.</p>
<p>Colette Kress: Sure. Thanks for the question as we start out here. I think when we had discussed our overall data center business three months ago, we did indicate that our visibility as we turned into the new calendar year was low. We had a challenge in terms of completing some of the deals at the end of that quarter. As we moved into Q1, I think we felt solid in terms of how we completed. We saw probably a combination of those moving forward, continuing with our CapEx expenditures and building out in terms of what they need for the data centers. Some others are still in terms of a pause. So, as we look in terms of &ndash; with Q2, I think we see a continuation of what we have in terms of the visibility not the best visibility going forward, but still rock solid to what we think are our benefits of what we provide in terms of a platform. Our overall priorities are aligned to what we see with the hyperscale as well as the enterprises as we think about using AI in so many of their different workloads. But, we&rsquo;ll just have to see as we go forward how this turns out. But right now, visibility probably just remains the same about as where we were when we started three months ago.</p>
<p>Aaron Rakers: Okay. And then, as a quick follow-up on the gaming side last quarter you talked about that being down I think it was termed as being down slightly for the full year. Is that still the expectation or how has that changed?</p>
<p>Colette Kress: So, at this time, we don&rsquo;t plan on giving a full year overall guidance. I think our look in terms of gaming all of the still drivers that we thought about earlier in the quarter and we talked about our Investor Day and we have continued to talk about are still definitely in the line. While the drivers of our gaming business and Turing RTX for the future are still on track. But, we&rsquo;re not providing guidance at this time for the full year.</p>
<p>Operator: And your next question comes from line of Harlan Sur with JPMorgan.</p>
<p>Harlan Sur: Good afternoon. Thanks for taking my question. On the last earnings call, you had mentioned China gaining demand is a headwind. At the Analyst Day in mid-March, I think Jen-Hsun had mentioned that the team was already starting to see better demand trends out of China maybe given the relaxed stance on gaming bans. Do you anticipate continued China gaming demand on a go forward basis and maybe talk about some of the dynamics driving that demand profile in the China geography?</p>
<p>Jen-Hsun Huang: Sure. China looks like fine. I think China has stabilized. The gaming market in China is really vibrant and it continues to be vibrant. Tencent&rsquo;s releasing new games. I think you might have heard that Epic stores now open in Asia and games are available from the West. So, there are all kinds of positive signs in China. There&rsquo;s some 300 million PC gamers in China and. And then, people are expecting it to grow. We&rsquo;re expecting the total number of gamers to continue to grow from the 1 plus billion PC gamers around the world to something more than that. And so, things look fine.</p>
<p>Harlan Sur: Thanks for that. And then, as a follow-up, a big part of the demand profile in the second half of the year for the gaming business is always the lineup of AAA rated games. Obviously, you guys have a very close partnership with all of the game developers. How does the pipeline of new games look, kind of they get launched October, November timeframe either a total number of blockbuster games and also games supporting you know real-time great racing as well as some of your deal assess capabilities?</p>
<p>Jen-Hsun Huang: Yes. Well, it&rsquo;s seasonal second half the year, we expect to see some great games. We won&rsquo;t preannounce anybody else games for them. But, this is this is a great PC cycle because it is the end of the console cycle. And PCs are where the actions at these days. With Battle Royale and Esports and so much social going on, the PC gaming ecosystem is just really vibrant. Our strategy with RTX was to take a lead and move the world to Ray tracing. And at this point I think it&rsquo;s fairly safe to say that that the leadership position that we&rsquo;ve taken has turned into a movement that has turned next generation gaming Ray tracing into a standard. Almost every single game platform will have to have Ray tracing and some of them already announced it and the partnerships that we&rsquo;ve developed are fantastic Microsoft DXR is supporting Ray tracing, Unity supporting ray tracing, Epic is supporting Ray tracing, leading publishers like EA has adopted RTX and supporting Ray tracing and movie studios, Pixar has adopted &ndash; announced that they&rsquo;re using RTX and will use artifacts to accelerate their rendering of films. And so, Adobe and Autodesk jumped on to RTX and that will bring Ray tracing to their content and their tools. And so, I think at this point it&rsquo;s fair to say that that Ray tracing is the next generation and it&rsquo;s going to be adopted all over the world.</p>
<p>Operator: And your next question comes from the line of Timothy Arcuri with UBS.</p>
<p>Timothy Arcuri: Thank you. I guess the first question is for Colette. So, what went into decision to pull for your guidance versus just cutting it. Is it really just fear around how long it could take for you no data center to come back? Thank you.</p>
<p>Colette Kress: Yes. I&rsquo;ll start off here and kind of go back to where our thoughts were in Q1 and why we provided full year guidance when we were in Q1. When we looked at Q1 and what we are guiding we understood that it was certainly an extraordinary quarter something that we didn&rsquo;t feel was a true representative of our business. And we wanted to get a better view of our trajectory of our business in terms of going forward. We are still experiencing I think the uncertainty as a result of the pause in terms of &ndash; with the overall hyperscale data centers. And we do believe that&rsquo;s going to extend into Q2. However, we do know and expect that our Q2 &ndash; assuming our H2 will likely be sizably larger than our overall H1. And the core dynamics of our business at every level is exactly what we expected. Just that said though, we&rsquo;re going to return to just quarterly guidance at this time.</p>
<p>Timothy Arcuri: Okay. Thanks. And then, just as a follow-up, can you give us some even qualitative if not quantitative sense of the $320 million incremental revenue for July. How that breaks out is the thinking sort of that data center is going to be flat to maybe up a little bit and pretty much the remainder of the growth comes from gaming. Thanks.</p>
<p>Colette Kress: Yes. So, when you think about our growth between Q1 and Q2, yes, we do expect in terms of our gaming to increase. We do expect our Nintendo switch to start again in sizable amount. Once we move into Q2 and we do at this time expect probably our data center business to grow.</p>
<p>Operator: And your next question comes from line of Toshiya Hari with Goldman Sachs.</p>
<p>Toshiya Hari: Thanks for taking the question. Jen-Hsun, I had a follow up on the data center business. I was hoping you could provide some color in terms of what you&rsquo;re seeing not only from your hyperscale customers which you&rsquo;ve talked extensively on, but more on the enterprise and the HP side of your business and specifically on the hyperscale side. You guys talk about this pause that you&rsquo;re seeing from your customer base. When you&rsquo;re having conversations with your customers, did they give you a reason as to why they&rsquo;re pausing is it, too much inventory of GPUs and CPUs and so on and so forth? Or is it, optimization giving them extra capacity? Is it caution on their own business going forward? Or is it a combination of all the above? Any color on that would be helpful too. Thank you.</p>
<p>Jen-Hsun Huang: Hyperscale are digesting the capacity they have. At this point, I think it&rsquo;s fairly clear that in the second half of last year they took on a little bit too much capacity. And so, everybody is has paused to give themselves a chance to digest. However, our business on inference is doing great. And we&rsquo;re working with CSPs all over the world to accelerate their inference models. Now the reason why recently the inference activity has gotten just off the charts because of breakthroughs in what we call conversational AI. In fact, today I think I just saw it today, but have known about this work for some time. Harry Shum&rsquo;s Group, Microsoft AI Research Group today announced their multitask DNN, general language understanding model and it broke benchmark records all over the place. And basically, what this means is the three fundamental components of conversational AI. which is speech recognition, natural language understanding which this multitask DNN is a breakthrough in and it&rsquo;s based on a piece of work that Google did recently called BERT. And then, text to speech all of the major pieces of a conversational AI are now put together. Of course, it&rsquo;s going to continue to evolve, but these models are gigantic to train. And in the case of Microsoft&rsquo;s network was trained on vault to GPUs and these systems require large amounts of memory, the models are enormous takes an enormous amount of time to train these systems. And so, we&rsquo;re seeing a breakthrough in conversational AI and across the board Internet companies would like to make their AI much more conversational. So that you can access through phones and smart speakers and be able to engage AI practically everywhere. The work that we&rsquo;re doing in industries makes a ton of sense. We&rsquo;re seeing AI adoption in just about all the industries from transportation to healthcare to retail to logistics, industrials, agriculture. And the reason for that is because they have a vast amount of data that they&rsquo;re collecting and I heard a statistic just the other day from a talk to [indiscernible] that some 90% of today&rsquo;s data was created just two years ago and it&rsquo;s being created by and gathered by these industrial systems all over the world. And so, if you want to put that data to work and you could create the models using our systems, our GPUs for training, and then you can extend that all the way out to the edge. This last quarter, we started to talk about our enterprise server based on T4. This inference engine that has been really successful for us at the CSPs is now going out into the edge and we call them edge servers and enterprise servers. And these edge systems are going to do AI basically instantaneously. It&rsquo;s too much data to move all the way to the cloud. You might have data sovereignty concerns, you want to have very, very low latency, maybe it needs to have multi-sensor fusion capabilities, so it understands the context better. For example, what it sees and what it hears has to be harmonious. And so, you need that kind of AI, those kind of sensor computing at the edge. And so, we&rsquo;re seeing a ton of excitement around this area. Some people call it the intelligent edge. Some people call edge computing and now with 5G networks coming, we&rsquo;re seeing a lot of interest around the edge computing servers that we&rsquo;re making. Those are the activity that we&rsquo;re seeing.</p>
<p>Toshiya Hari: Thank you. As a quick follow-up on the gaming side, Colette, can you characterize product mix within gaming. You saw in the current quarter, you cited mix as one of the key reasons why gross margins were down year-over-year albeit off a high base going into Q2 in the back half. Would you expect SKU mix within gaming to improve or stay the same? I ask because it&rsquo;s important for gross margins obviously. Thank you.</p>
<p>Colette Kress: Yes. When you look at our sequential gross margin increase that will be influenced by our larger revenue or larger revenue and better mix, which you&rsquo;re correct is our largest driver of our gross margin. However, we will be beginning the Nintendo switch back up and that does have lower gross margins than the company average influencing therefore our Q2 gross margin guidance that we provided. As we look forward towards the rest of the year, we think mix and the higher revenue again will influence and likely rise our overall gross margins for the full year.</p>
<p>Operator: And your next question comes from line of Joe Moore with Morgan Stanley.</p>
<p>Joe Moore: Great. Thank you. We&rsquo;ve talked quite a bit about GeForce now in the prepared remarks and at the Analyst Day. It seems like cloud gaming is going to be a big topic at [83] [ph]. Is that going to be your preferred way to go-to-market with cloud gaming and do you expect to sell GPUs to sort of traditional cloud vendors in non-GeForce NOW fashion?</p>
<p>Jen-Hsun Huang: Yes. Our strategy for cloud gaming is to extend our PC position for GeForce gamers into the cloud. And our strategy for our building out our network is partnerships with telcos around the world. And so, we&rsquo;ll build out some of it. And on top of the service, we have our entire PC gaming stack and when we host the service, we will move toward a subscription model. And with our telcos around the world who would like to provision the service at their edge servers and many of them would like to do so in conjunction with their 5G telco services to offer cloud gaming as a differentiator. In all of these different countries where PC exposure has been relatively low. We have an opportunity to extend our platform out to that billion PC gamers. And so, our that&rsquo;s our basic strategy. And we also offer our edge server platform to all of the cloud service providers. Google has NVIDIA GPU graphics in the cloud. Amazon has NVIDIA GPU graphics in the cloud and Microsoft has NVIDIA GPU graphics in the cloud. And these GPUs will be fantastic also for cloud gaming and workstation graphics and also Ray tracing. And so, the platform is capable of running all of the things that NVIDIA runs and we try to put it in every data center, in every cloud from every region that&rsquo;s possible.</p>
<p>Joe Moore: Thank you very much.</p>
<p>Operator: And your next question comes the line of Vivek Arya with Bank of America Merrill Lynch.</p>
<p>Vivek Arya: Thanks for taking my question. I actually had a clarification for Colette and a question for Jen-Hsun. Colette, are you now satisfied that the PC gaming business is operating at normal levels, when you look at Q2 guidance like all the issues regarding inventory and ratios are they over? Or do you think that the second half of the year is more than normalized run rate for your PC gaming business? And then, Jen-Hsun, on the data center &ndash; NVIDIA has dominated the training market inference sounds a lot more fragmented and competitive. There&rsquo;s a lot of talk of software being written more on the framework level. How should we get the confidence that at your lead-in training will help you maintain good lead and inference also? Thank you.</p>
<p>Colette Kress: Thanks for the question. So, let&rsquo;s start with your first part of the question regarding how we reached overall normalized gaming levels. When we look at our overall inventory in the channel, we believe that this is relatively behind us and moving forward that it will not be an issue. Going forward, we will probably reach normalized level for gaming somewhere between Q2 and Q3 similar to our discussion that we had back at Analyst Day and at the beginning of the quarter.</p>
<p>Jen-Hsun Huang: NVIDIA strategy is accelerated computing. It is very different than accelerator strategy. For example, if you were building a smart microphone, you need an accelerator for speech recognition ASR. Our company is focused on accelerated computing. And the reason for that is because the world&rsquo;s body of software is really gigantic and the world&rsquo;s body of software continues to evolve and AI is nowhere near done. We&rsquo;re probably at the first couple of innings of AI of that. And so, the amount of software and the size of the models are going to have to continue to evolve. Our accelerated computing platform is designed to enable the computer industry to bring forward into the future all the software that exists today whether it&rsquo;s TensorFlow or Caffe or PyTorch or it could be a classical machine learning algorithms like XGBoost, which is actually right now the most popular framework in machine learning overall. And there are so many different types of classical algorithms and not to mention all of the handwritten engineered algorithms by programmers. And those algorithms and those hand engineered algorithms also would like to be mixed in with all of the deep learning or otherwise classical machine learning algorithms. This whole body of software doesn&rsquo;t run on a single function accelerator. If you would like the body of software to run on something, it would have to be sufficiently general purpose. And so, the balance that we made was we invented this thing called a Tensor Core that allows us to accelerate deep learning to the speed of light. Meanwhile, it has the flexibility of CUDA, so that we can bring forward everything in classical machine learning as people have started to see with RAPIDS and it&rsquo;s being announced being integrated into machine learning pipelines in the cloud and elsewhere. And then, also all of the high-performance computing applications or computer vision algorithms, image processing algorithms that that don&rsquo;t have deep learning or machine learning alternatives. And so, our company is focused on accelerated computing. And speaking of inference that&rsquo;s one of the reasons why we&rsquo;re so successful in inference right now. We&rsquo;re seeing really great pickup. And the reason for that is because the type of models that people want to run on one application and let&rsquo;s just use one application, one very, very exciting one, conversational AI, you would have to do speech recognition, you would have to then do natural language understanding to understand what did the speeches &ndash; you might have to convert, you have to translate to another language. Then you have to do something related to maybe making a recommendation or making a search and then after that you have to convert that recommendation and search and the intent into speech. While some of it could be 8-bit integer, some of it really wants to be 16-bit floating point in some of it because of the development state of it may want to be in 32-bit floating point. And so, the mix precision nature and the computational algorithm nature, flexibility nature of our approach make it possible for cloud providers and people who are developing AI applications. To not have to worry about exactly what model it runs or not, we run every single model. And if it doesn&rsquo;t currently run well, we&rsquo;ll help you make it run. And so, the flexibility of our architecture and the incredible performance in deep learning is really a great balance and allows customers to deploy it easily. So, our strategy is very different than an accelerator. I think the only accelerators that I really see successful at the moment are the ones that go into smart speakers. And surely there are a whole bunch being talked about, but I think the real challenge is how to make it run real workloads. And we&rsquo;re going to keep cranking along in our current strategy and keep raising the bar as we have in the past.</p>
<p>Vivek Arya: Thank you.</p>
<p>Operator: And your next question comes from line of Stacy Rasgon with Bernstein Research.</p>
<p>Stacy Rasgon: Hi, guys. Thanks for taking my question. This is a question for Colette. Colette, you said inference and rendering within data center were both up very strongly, but I guess that has to imply that like the training flash acceleration pieces is quite weak even weaker than the overall. And given those should be adding to efficiency, I&rsquo;m just surprised it&rsquo;s down that much. Is this truly just digestion? I mean is it share I mean like your competitor is now shipping some parts here? I mean I guess how do we get confidence that just we haven&rsquo;t seen a ceiling on this? I mean do you think given the trajectory you can exit the year above the prior peaks I guess you kind of have to feel given at least the qualitative outlook on the cycle. I guess maybe just any color you can give us on any of those trends would be super helpful.</p>
<p>Colette Kress: So, as we discussed, Stacy. We are targeting many of the hyperscale definitely purchasing in terms of the inferencing into the installment that it continues. Also in terms of the training; the training instances that they will need for the cloud or for internal use, absolutely. We have some that have pods and going through all those period, so that we do believe because this will come back. We do believe as we look out into the future that they will need that overall deep learning for much of their research as well as many of their workloads. So, no concern on that. But right now, we do see a pause. I will turn it over to Jen-Hsun to see if he has additional comments.</p>
<p>Jen-Hsun Huang: Let&rsquo;s see. I think that that when it comes down to training, if your infrastructure team tells you not to buy anything. The thing that suffers is time to market and in some amount of experimentation that allows you to better pause and waiting longer. And then, I should &ndash; I think that for computer vision type of algorithms and recommendation type of algorithms those that posture may not be may not be impossible. However, the type of work that that everybody is now jumping on top of which is natural language understanding and conversational AI and the breakthrough that Microsoft just announced. If you want to keep up with that you&rsquo;re going to have to buy much, much larger machines. And I&rsquo;m looking forward to that and I expect that that&rsquo;s going to happen. But in the latter part of last year Q4 and Q1 of this year, we did see pause from the hyperscalers. But, I don&rsquo;t expect it to last.</p>
<p>Stacy Rasgon: Got it. This is a quick follow-up. I just wanted to ask about the regulatory around Mellanox in the context of what we&rsquo;re seeing out of China now. How do we sort of gauge the risk of potential further deterioration in relationship sort of spilling over on the regulatory front around deal. I we&rsquo;ve seen that obviously with some of the other large deals in the space. What are your thoughts on that?</p>
<p>Jen-Hsun Huang: Well, on first principles. The acquisition is going to enable data centers around the world whether it&rsquo;s U.S. or elsewhere China to be able to advance much, much more quickly. Now we&rsquo;re going to invest and building infrastructure technology and as a combined company, we&rsquo;ll be able to do that much better. And so, this is good for customers and it&rsquo;s great for customers in China. The two matters whether it&rsquo;s &ndash; the two matters that we&rsquo;re talking about just are different. One is related to competition in a &ndash; with respect to our acquisition to competition in the market. And the other is related to trade. And so, the two matters are just different. And in our particular case, we bring so much value to the marketplace in China. I mean I&rsquo;m confident that the market will see that.</p>
<p>Operator: And your next question comes from the line of C.J. Muse with Evercore ISI.</p>
<p>C.J. Muse: Yes. Good afternoon and thank you for taking my question. I guess a question on the non-cloud part of your datacenter business. If you think about the trends you&rsquo;re seeing in enterprise virtualization and HPC and all the work you&rsquo;re doing around RAPIDS, rendering et cetera. Can you kind of talk through the visibility you have today for that part of your business, I think that&rsquo;s roughly 50% of the mix, so is at a piece that you feel confident can grow in 2019 and any color around that would be appreciated.</p>
<p>Jen-Hsun Huang: We expected to grow in 2019. A lot of our T4 inference work is related to what people call edge computing and it has to be done at the edge because the amount of data that otherwise would be transferred to the cloud is just too much, has to be done at the edge because of data sovereignty issues and data privacy issues. And it has to be done at the edge because the latency requirement is really, really high. It has to respond basically like a reflex and to make a prediction or make a suggestion or stop the piece of machinery instantaneously. And so a lot of that work that we&rsquo;re doing in T4 inference is partly in the cloud, a lot of it is at the edge. T4 servers for enterprise were announced, I guess about halfway through the quarter and the OEMs are super excited about that because the number of companies in the world who want to do data analytics &ndash; predictive data analytics is quite large. And the size of the data is growing so significantly and with Moore&rsquo;s Law ending, it&rsquo;s really hard to power through terabytes of data at a time. And so, we&rsquo;ve been working on building the software stack from the new memory architectures and storage architectures all the way to the computational middleware and it&rsquo;s called RAPIDS and I appreciate you saying that. And that&rsquo;s being put together in the activity and get hub is just fantastic. As you can see all kinds of companies jumping in to make contributions because they would like to be able to take that open source software and run it in their own data center on our GPUs. And so, I expect the enterprise side of our business both for enterprise big data analytics or for edge computing to be a really good growth driver for us this year.</p>
<p>C.J. Muse: As a follow up, real quickly on auto. It&rsquo;s a business that you&rsquo;ve talked about more R&amp;D focus. But clearly, I think it surprised positively, what&rsquo;s the visibility like there and how should we think about growth trajectory into the second half of the year?</p>
<p>Jen-Hsun Huang: Our Automotive Strategy has several components. There&rsquo;s the engineering component of it where we &ndash; our engineers and their engineers have to co-develop the autonomous vehicles. And then there&rsquo;s three other components; there&rsquo;s the component of AI computing infrastructure, we call DGX and or any of the OEM servers that include our GPUs that are used for developing the AIs. The cars are collecting a couple of terabytes per day per test card. And all of that data has to be powered through and crunched through in the data center. And so, we have an infrastructure of what we call DGX that people could use. And so, we&rsquo;re seeing a lot of success there. We just announced this last quarter a new infrastructure called Constellation that lets you essentially drive thousands and thousands of test cars in your data center. And they&rsquo;re all going through a pseudo directed random or directed scenarios that allows you to either test untestable scenarios or regress against previous scenarios and we call that Constellation. And then, lastly, after working on a car for several years, we would install the computer inside the car and we call that drive. And so, these are these are the four components of opportunities that we have in the automotive industry. We&rsquo;re doing great in China. There&rsquo;s a whole bunch of electric vehicles being created, the robot taxis developments around the world largely using NVIDIA technology. We recently announced a partnership with Toyota. There&rsquo;s a whole bunch of stuff that we&rsquo;re working on. I&rsquo;m anxious to announce them to you. But this is an area that that &ndash; is the tip of the iceberg of a larger space we call robotics and computing at the edge. But if you think about the basic computational pipeline of a self-driving car, it&rsquo;s no different essentially than a smart retail or the future of computational medical instruments, agriculture, industrial inspection delivery drones are all basically use essentially the same technique. And so, this is the this is the foundational work that we do for a larger space that people call the intelligent as your computing at the edge.</p>
<p>Operator: Your next question comes from line of Chris Caso with Raymond James.</p>
<p>Chris Caso: Thank you. Good afternoon. First question is on notebooks and just to clarify what&rsquo;s been different from your expectations this year, is it simply that the OEMs didn&rsquo;t launch the new models you&rsquo;d expected given the shortage or is it more just about unit volume. And then, just following up on that. What&rsquo;s your level of confidence and that coming back to be a driver as you go into the second half of the year?</p>
<p>Jen-Hsun Huang: In Q2, we were &ndash; we had to deal with some CPU shortage issues at the OEMs. It&rsquo;s improving, but the initial ramp will be affected. And so, the CPU shortage situation has been described fairly broadly and that&rsquo;s affected our initial ramp. We don&rsquo;t expect it to affect our ramp going forward. And the new category of gaming notebooks that we created called Max-Q has made it possible for really amazing gaming performance to fit into a thin and light. And these new generations of notebooks with our Max-Q design and the Turing GPU which is super energy efficient, in combination made it possible for OEMs to create notebooks that are both affordable all the way down to $799 thin and really delightful all the way up to something incredible with a RTX 2080 and a 4K display. And these are thin notebooks that are really beautiful that people would love to use. And the invention of the Max-Q design method and all the software that went into it that we announced last year, we had &ndash; I think last year, we had some 40 notebooks or so maybe a little bit less than that. And this year, we have some hundred notebooks that are being designed at different price segments by different OEMs across different regions. And so, I think this year is going to be quite a successful year for notebooks. And it&rsquo;s also the most successful segment of consumer PCs. It&rsquo;s the fastest growing segment. It is very largely under penetrated because until Max-Q came along, it wasn&rsquo;t really possible to design a notebook that is both great and performance and experience and also something that a gamer would like to own. And so finally, we&rsquo;ve been able to solve that difficult puzzle and create a powerful gaming machines that are inside a notebook that&rsquo;s really wonderful to own and carry around. And so, this is going to be a really &ndash; this is a fast-growing segment and all the OEMs know it and that&rsquo;s why they put so much energy into creating all these different types of designs and styles and sizes and shapes and we have 100 Turing GPU notebooks gaming PCs ramping right now.</p>
<p>Chris Caso: It&rsquo;s very helpful. Thank you. As a follow-up, I just want to follow up on some of the previous questions on the automotive market. We&rsquo;ve been talking about it for a while. Obviously, the design cycles are very long, so you do have some visibility and I guess the question is, when can we expect an acceleration of auto revenue is next year the year. And then, what would be the driver of that in terms of dollar contribution. I presume some at level two plus things you&rsquo;ve been talking about would probably most likely there given the amount of volume there, if you can confirm that and just give some color on expectations for drivers?</p>
<p>Jen-Hsun Huang: Yes. Level 2+ call it 2020, late 2021 or 2022-ish. So that&rsquo;s Level 2+. I would say 2019 very, very early for robot taxis, next year substantially more volume for robot taxis 2021 bigger volumes for robot taxis. The ASP differences, the amount of computation you put into a robot taxi because of sensor resolution&rsquo;s, sensor diversity and redundancy, the computational redundancy and the richness of the algorithm all of it put together it&rsquo;s probably an order of magnitude plus in computation and so the economics would reflect that. And so that robot taxi is kind of like next year, year after ramp and then think of Level 2+ as 2021, 2022. Overall, remember that our economics come from four different parts. And so there&rsquo;s the NRE components of it. There&rsquo;s the AI development infrastructure, computing infrastructure part of it, the simulation part of it called Constellation, and then the economics of the car. And so, we just announced Constellation, the enthusiasm around it is really great. Nobody should ever ship anything they don&rsquo;t simulate. And my expectation is that billions of miles will get simulated inside a simulator long before they&rsquo;ll ship it. And so that&rsquo;s a great opportunity for Constellation.</p>
<p>Operator: And the next question comes from line of Matt Ramsay with Cowan.</p>
<p>Matt Ramsay: Thank you very much. Good afternoon. I have two questions, one for Jen-Hsun and one for Colette. I guess Jen-Hsun you&rsquo;ve done, you said in many forums that move down to the new process noted 7-nanometer across the business was not really sufficient to have a platform approach and I agree with that. But, maybe you could talk a little bit about your product plans at least in general terms around 7-nanometer franchising in the gaming business and also in your training accelerator program? And I wonder if that might be waiting for some of those products or at least the anticipation of those might be the cause of a little bit of a pause here. And secondly, Colette maybe you could talk us through your expectations. I understand there&rsquo;s a lack of visibility in certain parts of the business on revenue that maybe you could talk about OpEx trends through the rest of the year where you might have a little more visibility. Thank you.</p>
<p>Jen-Hsun Huang: The entire reason for Q4 and Q1 is attributed to oversupply in the channel as a result of cryptocurrency, has nothing to do with Turing in fact. Turing is off to a faster start than Pascal was. And it continues to be on a faster pace than Pascal was. And so, the pause in gaming is now behind us, we&rsquo;re on a growth trajectory with gaming, RTX has took the lead on Ray tracing and is now going to become the standard for next generation gaming support from basically every major platform and software provider on the planet. And our notebook growth is going to be really great because of the Max-Q design that we invented and the last couple of quarters have also intersected with overlapped with the seasonal slowdown that &ndash; not so, but build that the seasonal builds of the Nintendo switch and we&rsquo;re going to go back to normal build cycle. And as Colette said earlier somewhere between Q2 and Q3, we&rsquo;ll get back to normal levels for gaming. And so we&rsquo;re off to a great start in Turing and I&rsquo;m super excited about that. And then, in the second half of the year, we would have fully ramped up from top to bottom, our Turing architecture spanning everything from 179 to as high performance as you like. And we have the best price best performance and best GPU at every single price point. And so, I think we&rsquo;re in pretty good shape. In terms of process notes we tend to design our own process with TSMC. If you look at our process and you measure its energy efficiency, it&rsquo;s off the charts. And in fact, if you take our Turing and you compare it against a 7-nanometer GPU on energy efficiency, it&rsquo;s incomparable. In fact, the world&rsquo;s 7-nanometer GPU already exists and it&rsquo;s easy to go and pull that and compare the performance and energy efficiency against one of our current GPUs. And so that the real focus for our engineering team is to engineer a process that makes sense for us and to create an architecture that is energy efficient. And the combination of those two things allows us to sustain our leadership position. Otherwise, buying off the shelf process is something that we can surely do, but we want to do much more than that.</p>
<p>Colette Kress: And to the second question regarding OpEx trajectory for the rest of the year. We&rsquo;re still on track to our thoughts on leaving the fiscal year with the year-over-year growth and overall OpEx on a non-GAAP basis in a high single digit. We&rsquo;ll see probably an increase sequentially quarter-to-quarter along there. But our year-over-year growth start to decline as we will not be growing at the speed that we did in this past year. But, I do believe we&rsquo;re on track to meet that goal.</p>
<p>Operator: And I&rsquo;ll now turn the call back over to Jen-Hsun for any closing remarks.</p>
<p>Jen-Hsun Huang: Thanks everyone. We&rsquo;re glad to be returning to growth. We are focused on driving three growth strategies. First, RTX ray tracing. It&rsquo;s now clear that ray tracing is the future of gaming and digital design. And NVIDIA RTX is leading the way with the support of Microsoft DXR, Epic, Unity, Adobe and Autodesk. Game publishers like EA, movie studios like Pixar, industry support has been fantastic. Second, accelerated computing and AI computing, the pause in hyperscale spending will pass. Accelerated computing and AI are the greatest forces in computing today and NVIDIA is leading these movements. Whether cloud or enterprise or AI at the edge for 5G or industries NVIDIA is one scalable architecture from cloud to edge is a focal point platform for the industry to build AI upon. Third robotics, some call it embedded AI, some edge AI or autonomous machines. The same computing architecture is used for self-driving cars, pick and place robotics arms, delivery drones and smart retail stores. Every machine that move or machines that watch other things that move whether with driver or driverless will have robotics and AI capabilities. Our strategy is to create an end-to-end platform that spans NVIDIA&rsquo;s DGX AI computing infrastructure to NVIDIA Constellation simulation to NVIDIA AGX embedded AI computing. And finally, we&rsquo;re super excited about the pending acquisition of Mellonox. Together we can advance cloud and edge architectures for HPC and AI computing. See you next quarter.</p>
<p>Operator: And this concludes today&rsquo;s conference call. You may now disconnect.</p>

              


            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small">„Çø„Ç∞</span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://half-broken-engineer.github.io/tags/nvda/">NVDA</a>

                  </div>
                
              
            
            
<div class="post-actions-wrap">
  <nav >
    <ul class="post-actions post-action-nav">
      
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://half-broken-engineer.github.io/2019/08/nvda_2020_q2/" data-tooltip="NVDA_2020_Q2" aria-label="Ê¨°: NVDA_2020_Q2">
          
              <i class="fa fa-angle-left"></i>
              <span class="hide-xs hide-sm text-small icon-ml">Ê¨°</span>
            </a>
        </li>
        <li class="post-action">
          
            <a class="post-action-btn btn btn--disabled">
          
              <span class="hide-xs hide-sm text-small icon-mr">Ââç</span>
              <i class="fa fa-angle-right"></i>
            </a>
        </li>
      
    </ul>
  </nav>
<ul class="post-actions post-action-share" >
  
    <li class="post-action hide-lg hide-md hide-sm">
      <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="„Åì„ÅÆË®ò‰∫ã„ÇíÂÖ±Êúâ„Åô„Çã">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </a>
    </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://half-broken-engineer.github.io/2019/05/nvda_2020_q1/" title="Twitter„ÅßÂÖ±Êúâ" aria-label="Twitter„ÅßÂÖ±Êúâ">
          <i class="fab fa-twitter" aria-hidden="true"></i>
        </a>
      </li>
    
  
  
    <li class="post-action">
      <a class="post-action-btn btn btn--default" href="#disqus_thread" aria-label="„Ç≥„É°„É≥„Éà„ÇíÊÆã„Åô">
        <i class="far fa-comment"></i>
      </a>
    </li>
  
  <li class="post-action">
    
      <a class="post-action-btn btn btn--default" href="#top" aria-label="„Éà„ÉÉ„Éó„Å´Êàª„Çã">
      <i class="fa fa-arrow-up" aria-hidden="true"></i>
    
    </a>
  </li>
</ul>
</div>


            
  
    <div id="disqus_thread">
      <noscript>Please enable JavaScript to view the comments powered by Disqus.</noscript>
    </div>
    <script type="text/javascript">
      var disqus_config = function() {
        this.page.url = 'https:\/\/half-broken-engineer.github.io\/2019\/05\/nvda_2020_q1\/';
        
          this.page.identifier = '\/2019\/05\/nvda_2020_q1\/'
        
      };
      (function() {
        
        
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
          document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
          return;
        }
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        var disqus_shortname = 'hugo-tranquilpeak-theme';
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
      })();
    </script>
  


          </div>
        </article>
        <footer>
  <script type="text/javascript">
    MathJax = {
      tex: {
        inlineMath: [['$','$'], ['\\(','\\)']],
        processEscapes: true,
        tags: "ams",
        autoload: {
          color: [],
          colorV2: ['color']
        },
        packages: {'[+]': ['noerrors']}
      },
      chtml: {
        matchFontHeight: false,
        displayAlign: "left", 
        displayIndent: "2em"
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
        renderActions: {
           
          find_script_mathtex: [10, function (doc) {
            for (const node of document.querySelectorAll('script[type^="math/tex"]')) {
              const display = !!node.type.match(/; *mode=display/);
              const math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
              const text = document.createTextNode('');
              node.parentNode.replaceChild(text, node);
              math.start = {node: text, delim: '', n: 0};
              math.end = {node: text, delim: '', n: 0};
              doc.math.push(math);
            }
          }, '']
        }
      },
      loader: {
        load: ['[tex]/noerrors']
      }
    };
  </script>
  <script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/latest.js" id="MathJax-script"></script>
  
</footer>

      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="5">
        
<div class="post-actions-wrap">
  <nav >
    <ul class="post-actions post-action-nav">
      
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://half-broken-engineer.github.io/2019/08/nvda_2020_q2/" data-tooltip="NVDA_2020_Q2" aria-label="Ê¨°: NVDA_2020_Q2">
          
              <i class="fa fa-angle-left"></i>
              <span class="hide-xs hide-sm text-small icon-ml">Ê¨°</span>
            </a>
        </li>
        <li class="post-action">
          
            <a class="post-action-btn btn btn--disabled">
          
              <span class="hide-xs hide-sm text-small icon-mr">Ââç</span>
              <i class="fa fa-angle-right"></i>
            </a>
        </li>
      
    </ul>
  </nav>
<ul class="post-actions post-action-share" >
  
    <li class="post-action hide-lg hide-md hide-sm">
      <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="„Åì„ÅÆË®ò‰∫ã„ÇíÂÖ±Êúâ„Åô„Çã">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </a>
    </li>
    
      <li class="post-action hide-xs">
        <a class="post-action-btn btn btn--default" target="new" href="https://twitter.com/intent/tweet?text=https://half-broken-engineer.github.io/2019/05/nvda_2020_q1/" title="Twitter„ÅßÂÖ±Êúâ" aria-label="Twitter„ÅßÂÖ±Êúâ">
          <i class="fab fa-twitter" aria-hidden="true"></i>
        </a>
      </li>
    
  
  
    <li class="post-action">
      <a class="post-action-btn btn btn--default" href="#disqus_thread" aria-label="„Ç≥„É°„É≥„Éà„ÇíÊÆã„Åô">
        <i class="far fa-comment"></i>
      </a>
    </li>
  
  <li class="post-action">
    
      <a class="post-action-btn btn btn--default" href="#top" aria-label="„Éà„ÉÉ„Éó„Å´Êàª„Çã">
      <i class="fa fa-arrow-up" aria-hidden="true"></i>
    
    </a>
  </li>
</ul>
</div>


      </div>
      
<div id="share-options-bar" class="share-options-bar" data-behavior="5">
  <i id="btn-close-shareoptions" class="fa fa-times"></i>
  <ul class="share-options">
    
      <li class="share-option">
        <a class="share-option-btn" target="new" href="https://twitter.com/intent/tweet?text=https%3A%2F%2Fhalf-broken-engineer.github.io%2F2019%2F05%2Fnvda_2020_q1%2F" aria-label="Twitter„ÅßÂÖ±Êúâ">
          <i class="fab fa-twitter" aria-hidden="true"></i><span>Twitter„ÅßÂÖ±Êúâ</span>
        </a>
      </li>
    
  </ul>
</div>
<div id="share-options-mask" class="share-options-mask"></div>


    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-times"></i>
    </div>
    
      <img id="about-card-picture" src="https://half-broken-engineer.github.io/img/profile.png" alt="„Éó„É≠„Éï„Ç£„Éº„É´ÁîªÂÉè" />
    
    <h4 id="about-card-name">Half-Broken Engineer</h4>
    
      <div id="about-card-bio">ü§ñ„ÄÄ„ÄÄ„ÄÄ„ÄÄÂ£ä„Çå„Åã„Åë„ÅÆ„Ç®„É≥„Ç∏„Éã„Ç¢„ÄÄ„ÄÄ„ÄÄ„ÄÄüíª‰∏çÂÆâ„ÇíËß£Ê∂à„Åó„Åü„ÅÑ„Åã„Çâüí∞„ÅÆ„ÅäÂãâÂº∑„ÇÇ„Åô„Çã</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Engineer
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker-alt"></i>
        <br/>
        Japan
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://half-broken-engineer.github.io/images/cover.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/highlight.min.js" integrity="sha512-z+/WWfyD5tccCukM4VvONpEtLmbAm5LDu7eKiyMQJ9m7OfPEDL7gENyDRL3Yfe8XAuGsS2fS4xSMnl6d30kqGQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<script src="https://half-broken-engineer.github.io/js/script-yqzy9wdlzix4lbbwdnzvwx3egsne77earqmn73v9uno8aupuph8wfguccut.min.js"></script>


  
    <script async crossorigin="anonymous" defer integrity="sha512-gE8KAQyFIzV1C9+GZ8TKJHZS2s+n7EjNtC+IMRn1l5+WYJTHOODUM6JSjZhFhqXmc7bG8Av6XXpckA4tYhflnw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/apache.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-EWROca+bote+7Oaaar1F6y74iZj1r1F9rm/ly7o+/FwJopbBaWtsFDmaKoZDd3QiGU2pGacBirHJNivmGLYrow==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/go.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-GDVzAn0wpx1yVtQsRWmFc6PhJiLBPdUic+h4GWgljBh904O3JU10fk9EKNpVyIoPqkFn54rgL2QBG4BmUTMpiQ==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/http.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-UgZlma8NzkrDb/NWgmLIcTrH7i/CSnLLDRFqCSNF5NGPpjKmzyM25qcoXGOup8+cDakKyaiTDd7N4dyH4YT+IA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/less.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-lot9koe73sfXIrUvIPM/UEhuMciN56RPyBdOyZgfO53P2lkWyyXN7J+njcxIIBRV+nVDQeiWtiXg+bLAJZDTfg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/nginx.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-Zd3e7XxHP00TD0Imr0PIfeM0fl0v95kMWuhyAS3Wn1UTSXTkz0OhtRgBAr4JlmADRgiXr4x7lpeUdqaGN8xIog==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/puppet.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-qtqDO052iXMSP+5d/aE/jMtL9vIIGvONgTJziC2K/ZIB1yEGa55WVxGE9/08rSQ62EoDifS9SWVGZ7ihSLhzMA==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/scss.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-1NmkjnEDnwwwcu28KoQF8vs3oaPFokQHbmbtwGhFfeDsQZtVFI8zW2aE9O8yMYdpdyKV/5blE4pSWw4Z/Sv97w==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/stylus.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-B2wSfruPjr8EJL6IIzQr1eAuDwrsfIfccNf/LCEdxELCgC/S/ZMt/Uvk80aD79m7IqOqW+Sw8nbkvha20yZpzg==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/swift.min.js"></script>
  

  
    <script async crossorigin="anonymous" defer integrity="sha512-28oDiQZGKUVN6wQ7PSLPNipOcmkCALXKwOi7bnkyFf8QiMZQxG9EQoy/iiNx6Zxj2cG2SbVa4dXKigQhu7GiFw==" src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.1.0/languages/yaml.min.js"></script>
  


<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight > code, pre > code').each(function(i, block) {
    if (!$(this).hasClass('codeblock')) {
      $(this).addClass('codeblock');
    }
    hljs.highlightBlock(block);
  });
});
</script>




    
  </body>
</html>

